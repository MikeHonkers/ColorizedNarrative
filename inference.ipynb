{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddada56-87bc-4e98-88ac-39667b2704d7",
   "metadata": {},
   "source": [
    "Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8336a9f8-e2c2-4251-956f-a20a3548793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Загружаем SOVA-audiobooks-100k (только для val/test) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d1e060bb2847ed86d6d2bd1057d92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba7ee2e3a224d2aa5e791c8e1d5b387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4b1a91741d4540a340d73511ba4044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Нормализуем текст для val/test ...\n",
      "→ Фильтруем пустые/битые аудио ...\n",
      "[DATA] train: 99057  val: 1011  test: 1011\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "from datasets import load_dataset, Audio, config as ds_config\n",
    "\n",
    "\n",
    "BASE_DIR   = r\"W:\\whisper_sova\"\n",
    "DATA_DIR   = fr\"{BASE_DIR}\\data\"\n",
    "\n",
    "\n",
    "ds_config.TORCHCODEC_AVAILABLE = False\n",
    "\n",
    "DATASET_ID = \"MikeHonkers/SOVA-audiobooks-100k\"\n",
    "TARGET_SR  = 16000\n",
    "MIN_BYTES  = int(0.20 * TARGET_SR * 2)\n",
    "\n",
    "print(\"→ Загружаем SOVA-audiobooks-100k (только для val/test) ...\")\n",
    "ds = load_dataset(DATASET_ID, cache_dir=DATA_DIR, split=\"train\")\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.02, seed=42)\n",
    "train_ds, test_holdout = ds[\"train\"], ds[\"test\"]\n",
    "val_test = test_holdout.train_test_split(test_size=0.5, seed=42)\n",
    "val_ds, test_ds = val_test[\"train\"], val_test[\"test\"]\n",
    "\n",
    "train_ds = train_ds.cast_column(\"audio\", Audio(decode=False))\n",
    "val_ds   = val_ds.cast_column(\"audio\",   Audio(decode=False))\n",
    "test_ds  = test_ds.cast_column(\"audio\",  Audio(decode=False))\n",
    "\n",
    "def normalize_ru_text(s: str) -> str:\n",
    "    s = s.strip().replace(\"ё\", \"е\")\n",
    "    s = re.sub(r'[“”«»]', '\"', s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def prepare_batched(batch):\n",
    "    return {\"sentence\": [normalize_ru_text(t) for t in batch[\"text\"]]}\n",
    "\n",
    "print(\"→ Нормализуем текст для val/test ...\")\n",
    "train_ds = train_ds.map(prepare_batched, batched=True, desc=\"prepare train (for consistency)\")\n",
    "val_ds   = val_ds.map(prepare_batched,   batched=True, desc=\"prepare val\")\n",
    "test_ds  = test_ds.map(prepare_batched,  batched=True, desc=\"prepare test\")\n",
    "\n",
    "def has_audio_ref(ex):\n",
    "    a = ex.get(\"audio\", {})\n",
    "    return (a.get(\"path\") or a.get(\"bytes\")) is not None\n",
    "\n",
    "def looks_nonempty(ex):\n",
    "    a = ex.get(\"audio\", {})\n",
    "    if a.get(\"bytes\"):\n",
    "        return len(a[\"bytes\"]) >= MIN_BYTES\n",
    "    p = a.get(\"path\")\n",
    "    return bool(p) and os.path.exists(p) and os.path.getsize(p) >= MIN_BYTES\n",
    "\n",
    "print(\"→ Фильтруем пустые/битые аудио ...\")\n",
    "train_ds = train_ds.filter(has_audio_ref)\n",
    "val_ds   = val_ds.filter(has_audio_ref)\n",
    "test_ds  = test_ds.filter(has_audio_ref)\n",
    "\n",
    "train_ds = train_ds.filter(looks_nonempty)\n",
    "val_ds   = val_ds.filter(looks_nonempty)\n",
    "test_ds  = test_ds.filter(looks_nonempty)\n",
    "\n",
    "print(f\"[DATA] train: {len(train_ds)}  val: {len(val_ds)}  test: {len(test_ds)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03697bc-18aa-4a67-af92-68635606e525",
   "metadata": {},
   "source": [
    "Батч-оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47979580-2927-4908-843a-fda6ac07dd7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: val | items: 12 | greedy strict v2 | VAD top_db=40\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "C:\\Users\\Andrey\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\Andrey\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
      "The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#   137] dur=5.43s → 4.13s | max_new=25\n",
      "  REF: уже издалека метров за пятьдесят он закричал им чтобы заводили\n",
      "  HYP: уж и с далека метров за пятьдесят он закричал им чтобы заводили в течение час\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   582] dur=5.07s → 3.52s | max_new=22\n",
      "  REF: а теперь товарищи сказал сноуболл отбрасывая кисточку на нивы\n",
      "  HYP: а теперь товарищ я сказал сноуболла бросая кисточку на нивы в\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   867] dur=3.81s → 2.08s | max_new=16\n",
      "  REF: три корабля все-таки исчезли\n",
      "  HYP: три корабля все-таки исчезли и с днём\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   821] dur=6.06s → 5.25s | max_new=30\n",
      "  REF: боюсь что эту идею нам придется с негодованием отвергнуть огорченно сообщил мужчина\n",
      "  HYP: боюсь что эту идею нам придется с негодованием отвергнуть оберченно сообщил мужчинах а у\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   782] dur=3.00s → 2.18s | max_new=17\n",
      "  REF: белый клык обходился без этого\n",
      "  HYP: белый клык обходился без этого ааэээ в\n",
      "------------------------------------------------------------------------------------------\n",
      "[#    64] dur=12.87s → 11.42s | max_new=55\n",
      "  REF: что такое она поняла спросил гарри в смятении все еще озираясь вдруг еще раз услышит голос и сумеет определить откуда же он исходит\n",
      "  HYP: что такое она поняла спросил гарри смятение все еще озираясь вдруг еще раз услышит голос сумеет определить откуда же он не сходит и что это за хреба а то как вы можете понять я в этом случае\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   261] dur=5.22s → 3.94s | max_new=24\n",
      "  REF: ну мало ли питер место такое\n",
      "  HYP: ну мало ли питер место такое и сэрс ворота на ладони не выживали\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   120] dur=3.12s → 2.21s | max_new=17\n",
      "  REF: особенность вампиров о ней сказки не врут\n",
      "  HYP: особенно с вампиров они сказки не врут и так далее все это\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   507] dur=5.55s → 4.42s | max_new=26\n",
      "  REF: до сих пор в своем паршивом спортивном костюме ходишь как лоховка какая-то\n",
      "  HYP: для сих пор в своем паршивом спортивном костюме ходишь как лоховка\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#   779] dur=7.56s → 6.14s | max_new=33\n",
      "  REF: и возможно что это вызвано какой то причиной которую мы обнаружили слишком поздно\n",
      "  HYP: и возможно что это вызвано какой-то причиной которую мы обнаружили слишком поздно как вы\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   460] dur=7.89s → 7.33s | max_new=38\n",
      "  REF: боксер опустил копыто и собака повизгивая уползла в сторону\n",
      "  HYP: боксер опустил копыто и собака повизгивая уползла в сторону его шума на ладону с кем-ли\n",
      "------------------------------------------------------------------------------------------\n",
      "[#   483] dur=6.33s → 6.33s | max_new=34\n",
      "  REF: и как только что-нибудь случится немедленно явимся на место происшествия\n",
      "  HYP: и как только что-нибудь случится немедленно явимся на место происшествияю и в течение года вы можете увидеть себя так же не очень\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os, io, json, math, random\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from transformers import pipeline, WhisperForConditionalGeneration, WhisperProcessor\n",
    "from peft import PeftModel\n",
    "\n",
    "BASE_DIR      = r\"W:\\whisper_sova\"\n",
    "MODEL_DIR     = fr\"{BASE_DIR}\\model\"\n",
    "OUTPUT_DIR    = fr\"{BASE_DIR}\\output\"\n",
    "PROCESSOR_DIR = fr\"{OUTPUT_DIR}\\processor\"\n",
    "ADAPTER_DIR   = fr\"{OUTPUT_DIR}\\lora_adapter_fast\"\n",
    "MODEL_ID      = \"openai/whisper-small\"\n",
    "TARGET_SR     = 16000\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(PROCESSOR_DIR)\n",
    "base_model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID, cache_dir=MODEL_DIR, device_map=\"auto\")\n",
    "ft_model  = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "ft_model.eval()\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=ft_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    generate_kwargs={\n",
    "        \"task\": \"transcribe\",\n",
    "        \"language\": \"russian\",\n",
    "        \"num_beams\": 1,\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"no_repeat_ngram_size\": 4,\n",
    "        \"repetition_penalty\": 1.30,\n",
    "        \"length_penalty\": 0.0,\n",
    "        \"return_timestamps\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "def load_audio_field(audio_field):\n",
    "    if audio_field.get(\"bytes\"):\n",
    "        y, sr = sf.read(io.BytesIO(audio_field[\"bytes\"]), always_2d=False)\n",
    "    else:\n",
    "        y, sr = sf.read(audio_field[\"path\"], always_2d=False)\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "    return y.astype(np.float32), sr\n",
    "\n",
    "def strong_vad_trim(y, sr, top_db=40):\n",
    "    y = librosa.util.normalize(y, axis=0)\n",
    "    yt, _ = librosa.effects.trim(y, top_db=top_db)\n",
    "    return yt if yt.size >= int(0.5 * sr) else y\n",
    "\n",
    "def resample_to(y, sr, target_sr=TARGET_SR):\n",
    "    return y if sr == target_sr else librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "def save_tmp_wav(y, sr, fname=\"_vad_tmp.wav\"):\n",
    "    path = os.path.join(OUTPUT_DIR, fname)\n",
    "    sf.write(path, y, sr)\n",
    "    return path\n",
    "\n",
    "def adaptive_max_new_tokens(duration_s, scale=4.2, bias=8, hard_min=10, hard_max=64):\n",
    "    m = int(scale * duration_s + bias)\n",
    "    return max(hard_min, min(hard_max, m))\n",
    "\n",
    "random.seed(1)\n",
    "idxs = random.sample(range(len(val_ds)), k=min(12, len(val_ds)))\n",
    "\n",
    "print(f\"Split: val | items: {len(idxs)} | greedy strict v2 | VAD top_db=40\")\n",
    "print(\"-\"*90)\n",
    "for i, idx in enumerate(idxs):\n",
    "    ex = val_ds[idx]\n",
    "    ref = ex.get(\"sentence\") or ex.get(\"text\") or \"\"\n",
    "    y, sr = load_audio_field(ex[\"audio\"])\n",
    "    dur = len(y)/sr\n",
    "    y = resample_to(y, sr, TARGET_SR)\n",
    "    y = strong_vad_trim(y, TARGET_SR, top_db=40)\n",
    "    dur_trim = len(y)/TARGET_SR\n",
    "    wav_path = save_tmp_wav(y, TARGET_SR, fname=f\"_vadv2_{i}.wav\")\n",
    "\n",
    "    max_new = adaptive_max_new_tokens(dur_trim, scale=4.2, bias=8, hard_min=10, hard_max=64)\n",
    "    out = pipe(wav_path, generate_kwargs=dict(max_new_tokens=max_new))\n",
    "    hyp = out[\"text\"].strip()\n",
    "\n",
    "    print(f\"[# {idx:5d}] dur={dur:.2f}s → {dur_trim:.2f}s | max_new={max_new}\")\n",
    "    print(\"  REF:\", ref[:220])\n",
    "    print(\"  HYP:\", hyp[:220] + (\"…\" if len(hyp) > 220 else \"\"))\n",
    "    print(\"-\"*90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d436e1-f922-4480-80dc-927134321b40",
   "metadata": {},
   "source": [
    "Диаризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9c594-e8ee-4b79-9b09-e47a3bbc1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"******\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f3793-1999-4ad8-a84b-4c44d59e651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")  # или явно строкой\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline.to(device)\n",
    "\n",
    "print(\"Диаризация инициализирована на:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96261d23-43a7-4273-8eb3-948fa74ba8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diarize_and_transcribe(\n",
    "    y: np.ndarray,\n",
    "    sr: int,\n",
    "    global_wav_path: str,\n",
    "    diar_pipeline,\n",
    "    asr_pipe,\n",
    "    max_tokens_fn=adaptive_max_new_tokens,\n",
    "    min_seg_dur: float = 0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    y, sr       – аудиосигнал, уже приведённый к TARGET_SR.\n",
    "    global_wav_path – путь к этому же аудио (для pyannote).\n",
    "    diar_pipeline – pyannote.audio Pipeline (speaker-diarization-3.1).\n",
    "    asr_pipe    –  HF pipeline с LoRA-Whisper.\n",
    "    max_tokens_fn(duration_s) – функция для max_new_tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    out = diar_pipeline(global_wav_path)\n",
    "\n",
    "    if hasattr(out, \"speaker_diarization\"):\n",
    "        ann = out.speaker_diarization\n",
    "    else:\n",
    "        ann = out\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    for turn, _, speaker in ann.itertracks(yield_label=True):\n",
    "        start_s = float(turn.start)\n",
    "        end_s   = float(turn.end)\n",
    "        if end_s <= start_s:\n",
    "            continue\n",
    "        if (end_s - start_s) < min_seg_dur:\n",
    "            continue\n",
    "\n",
    "        start_idx = int(start_s * sr)\n",
    "        end_idx   = int(end_s * sr)\n",
    "        seg = y[start_idx:end_idx]\n",
    "\n",
    "        if seg.size < int(min_seg_dur * sr):\n",
    "            continue\n",
    "\n",
    "        duration_seg = (end_idx - start_idx) / sr\n",
    "        max_new = max_tokens_fn(duration_seg)\n",
    "\n",
    "        asr_out = asr_pipe(\n",
    "            {\"array\": seg, \"sampling_rate\": sr},\n",
    "            generate_kwargs=dict(max_new_tokens=max_new),\n",
    "        )\n",
    "        text = asr_out[\"text\"].strip()\n",
    "\n",
    "        segments.append(\n",
    "            {\n",
    "                \"speaker\": str(speaker),\n",
    "                \"start\": start_s,\n",
    "                \"end\": end_s,\n",
    "                \"text\": text,\n",
    "                \"duration\": duration_seg,\n",
    "                \"max_new_tokens\": max_new,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    segments.sort(key=lambda s: s[\"start\"])\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f4e36-1a72-4241-958c-aaa00d23f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Split: val | items: {len(idxs)} | greedy strict v2 | VAD top_db=40 + diarization\")\n",
    "print(\"-\"*90)\n",
    "for i, idx in enumerate(idxs):\n",
    "    ex = val_ds[idx]\n",
    "    ref = ex.get(\"sentence\") or ex.get(\"text\") or \"\"\n",
    "    y, sr = load_audio_field(ex[\"audio\"])\n",
    "    dur = len(y) / sr\n",
    "\n",
    "    y = resample_to(y, sr, TARGET_SR)\n",
    "    y = strong_vad_trim(y, TARGET_SR, top_db=40)\n",
    "    dur_trim = len(y) / TARGET_SR\n",
    "\n",
    "    wav_path = save_tmp_wav(y, TARGET_SR, fname=f\"_vadv2_{i}.wav\")\n",
    "\n",
    "    max_new = adaptive_max_new_tokens(dur_trim, scale=4.2, bias=8, hard_min=10, hard_max=64)\n",
    "    out = pipe(wav_path, generate_kwargs=dict(max_new_tokens=max_new))\n",
    "    hyp = out[\"text\"].strip()\n",
    "\n",
    "    print(f\"[# {idx:5d}] dur={dur:.2f}s → {dur_trim:.2f}s | max_new={max_new}\")\n",
    "    print(\"  REF:\", ref[:220])\n",
    "    print(\"  HYP:\", hyp[:220] + (\"…\" if len(hyp) > 220 else \"\"))\n",
    "\n",
    "\n",
    "    diar_segments = diarize_and_transcribe(\n",
    "        y,\n",
    "        TARGET_SR,\n",
    "        wav_path,\n",
    "        diar_pipeline=pipeline,\n",
    "        asr_pipe=pipe,\n",
    "        max_tokens_fn=adaptive_max_new_tokens,\n",
    "        min_seg_dur=0.7,\n",
    "    )\n",
    "    if diar_segments:\n",
    "        print(\"  Diarized transcript:\")\n",
    "        for seg in diar_segments:\n",
    "            print(\n",
    "                f'    [spk {seg[\"speaker\"]}] '\n",
    "                f'{seg[\"start\"]:6.2f}-{seg[\"end\"]:6.2f}s | '\n",
    "                f'max_new={seg[\"max_new_tokens\"]:2d} | '\n",
    "                f'{seg[\"text\"][:150]}{\"…\" if len(seg[\"text\"]) > 150 else \"\"}'\n",
    "            )\n",
    "    else:\n",
    "        print(\"  Diarized transcript: <empty / only noise>\")\n",
    "\n",
    "\n",
    "    print(\"-\"*90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01fa66-3020-45b8-be6c-8a63fd39e848",
   "metadata": {},
   "source": [
    "Свой файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a3838-a03f-4781-a131-83f8f8eaefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "AUDIO_FILE = \"videoplayback.m4a\"\n",
    "\n",
    "if not os.path.exists(AUDIO_FILE):\n",
    "    raise FileNotFoundError(f\"Не найден {AUDIO_FILE} рядом с ноутбуком. Текущая папка: {os.getcwd()}\")\n",
    "\n",
    "y, sr = librosa.load(AUDIO_FILE, sr=None, mono=False)\n",
    "if y.ndim > 1:\n",
    "    y = y.mean(axis=0)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "max_samples = int(20.0 * sr)\n",
    "if len(y) > max_samples:\n",
    "    y = y[:max_samples]\n",
    "dur_raw = len(y) / sr\n",
    "\n",
    "y16 = resample_to(y, sr, TARGET_SR)\n",
    "dur16 = len(y16) / TARGET_SR\n",
    "\n",
    "wav_path = save_tmp_wav(y16, TARGET_SR, fname=\"_film_20s_no_vad.wav\")\n",
    "\n",
    "print(f\"Файл: {AUDIO_FILE}\")\n",
    "print(f\"  исходный sr={sr}, dur≈{dur_raw:.2f}с (обрезано до 20с)\")\n",
    "print(f\"  после ресемплинга 16k: dur≈{dur16:.2f}с\")\n",
    "print(f\"  временный WAV для анализа: {wav_path}\")\n",
    "\n",
    "max_new_full = adaptive_max_new_tokens(\n",
    "    dur16,\n",
    "    scale=4.2,\n",
    "    bias=8,\n",
    "    hard_min=10,\n",
    "    hard_max=160,\n",
    ")\n",
    "asr_full = pipe(wav_path, generate_kwargs=dict(max_new_tokens=max_new_full))\n",
    "full_text = asr_full[\"text\"].strip()\n",
    "\n",
    "print(\"\\n=== Общая расшифровка (без диаризации) ===\")\n",
    "print(full_text)\n",
    "\n",
    "diar_segments = diarize_and_transcribe(\n",
    "    y16,\n",
    "    TARGET_SR,\n",
    "    wav_path,\n",
    "    diar_pipeline=pipeline,\n",
    "    asr_pipe=pipe, \n",
    "    max_tokens_fn=adaptive_max_new_tokens,\n",
    "    min_seg_dur=0.3,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Диаризация + ASR по спикерам (без внешнего VAD, min_seg_dur=0.3) ===\")\n",
    "if not diar_segments:\n",
    "    print(\"<нет голосовых сегментов / только шум>\")\n",
    "else:\n",
    "    for seg in diar_segments:\n",
    "        print(\n",
    "            f'[spk {seg[\"speaker\"]}] '\n",
    "            f'{seg[\"start\"]:6.2f}-{seg[\"end\"]:6.2f}s '\n",
    "            f'(dur={seg[\"duration\"]:.2f}s, max_new={seg[\"max_new_tokens\"]})'\n",
    "        )\n",
    "        print(\"   \", seg[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92d5d6-f9d9-4c7f-b1c3-225842ced2b1",
   "metadata": {},
   "source": [
    "Экспорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f24a9-1d65-4b2f-ba71-a4e0fe8a9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "if \"diar_segments\" not in globals() or not diar_segments:\n",
    "    raise RuntimeError(\"diar_segments пуст или не определён — сначала запусти ячейку с диаризацией.\")\n",
    "\n",
    "audio_file = globals().get(\"AUDIO_FILE\", \"unknown\")\n",
    "sample_rate = globals().get(\"TARGET_SR\", 16000)\n",
    "duration_sec = globals().get(\"dur16\", None)\n",
    "asr_model_id = globals().get(\"MODEL_ID\", \"whisper_lora\")\n",
    "diar_model_id = \"pyannote/speaker-diarization-3.1\"\n",
    "\n",
    "speaker_map = {}\n",
    "next_spk_idx = 0\n",
    "\n",
    "segments_json = []\n",
    "\n",
    "for i, seg in enumerate(diar_segments, start=1):\n",
    "    raw_spk = str(seg[\"speaker\"])\n",
    "    if raw_spk not in speaker_map:\n",
    "        speaker_map[raw_spk] = f\"S{next_spk_idx}\"\n",
    "        next_spk_idx += 1\n",
    "    spk_id = speaker_map[raw_spk]\n",
    "\n",
    "    seg_id = f\"seg_{i:04d}\"\n",
    "\n",
    "    start_t = round(float(seg[\"start\"]), 2)\n",
    "    end_t   = round(float(seg[\"end\"]), 2)\n",
    "\n",
    "    segments_json.append(\n",
    "        {\n",
    "            \"id\": seg_id,\n",
    "            \"start\": start_t,\n",
    "            \"end\": end_t,\n",
    "            \"speaker\": spk_id,     \n",
    "            \"speaker_raw\": raw_spk, \n",
    "            \"text\": seg[\"text\"],       \n",
    "            \"conf\": None,           \n",
    "            \"n_best\": [],            \n",
    "            \"uncertain_spans\": [],  \n",
    "        }\n",
    "    )\n",
    "\n",
    "export_obj = {\n",
    "    \"schema_version\": 1,\n",
    "    \"language\": \"ru\",\n",
    "    \"meta\": {\n",
    "        \"source\": audio_file,\n",
    "        \"sample_rate\": sample_rate,\n",
    "        \"duration\": duration_sec,\n",
    "        \"num_speakers\": len(speaker_map),\n",
    "        \"speaker_map\": speaker_map,\n",
    "        \"asr_model\": asr_model_id,\n",
    "        \"diarization_model\": diar_model_id,\n",
    "    },\n",
    "    \"segments\": segments_json,\n",
    "}\n",
    "\n",
    "\n",
    "base_out_dir = globals().get(\"OUTPUT_DIR\", os.getcwd())\n",
    "os.makedirs(base_out_dir, exist_ok=True)\n",
    "\n",
    "json_path = os.path.join(base_out_dir, \"videoplayback_20s_diarized.json\")\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(export_obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\" Экспортирован диаризованный транскрипт в: {json_path}\\n\")\n",
    "print(\"Пример (первые сегменты):\")\n",
    "print(json.dumps({**export_obj, \"segments\": export_obj[\"segments\"][:3]}, ensure_ascii=False, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
